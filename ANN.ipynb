{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaXhLzP9g60MPDBCM4tRKp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rameshavinash94/CMPE255_ANN/blob/main/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_xUXe7_X8Lv"
      },
      "source": [
        "## **IMPORTING LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OULZLGNkliz-"
      },
      "source": [
        "#Have tried multiple libraries\n",
        "#Download the necessary modules : spacy english language module, google universal sentece encoder, faiss-cpu, datasketch, annoy, nmslib\n",
        "!python -m spacy download en_core_web_md\n",
        "!pip install spacy_universal_sentence_encoder\n",
        "!pip install faiss-cpu\n",
        "!pip install datasketch\n",
        "!pip install annoy\n",
        "!pip install nmslib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO7tDjeciVyn"
      },
      "source": [
        "# Importing necessary modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from datasketch import MinHash, MinHashLSHForest\n",
        "import re\n",
        "import faiss\n",
        "import annoy\n",
        "import spacy_universal_sentence_encoder\n",
        "import nmslib\n",
        "from annoy import AnnoyIndex\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0UUWv-FYBW7"
      },
      "source": [
        "## **LOADING AND PREPROCESSING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "1MgqAK7iiLdg",
        "outputId": "fb4bdb93-a12e-4fe0-d8ef-e57b303113cb"
      },
      "source": [
        "#load the dataset\n",
        "papers = pd.read_csv(\"/content/papers.csv\")\n",
        "\n",
        "# Print out the head of the dataframe\n",
        "papers.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                         paper_text\n",
              "0     1  ...  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
              "1    10  ...  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
              "2   100  ...  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
              "3  1000  ...  Bayesian Query Construction for Neural\\nNetwor...\n",
              "4  1001  ...  Neural Network Ensembles, Cross\\nValidation, a...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NbhXbG9OFf6",
        "outputId": "22f64f10-9081-4fc6-9b74-1a48ddf6ce92"
      },
      "source": [
        "#check shape\n",
        "papers.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7241, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LRKvv91MtaC"
      },
      "source": [
        "#extracting papers that contains only abstract to avoid hugh chunk of processing in colab\n",
        "abstract_papers = papers[papers['abstract'] != \"Abstract Missing\"]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egq3QGMdLGaJ",
        "outputId": "50a394f8-e839-416c-f880-ba08e3d2287c"
      },
      "source": [
        "#check shape post filtering\n",
        "abstract_papers.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3924, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2sBjlN_pMSm0",
        "outputId": "17c647c6-82ae-4085-c8b5-cc22c7f39075"
      },
      "source": [
        "# Remove unnecssary columns\n",
        "final_dataset = abstract_papers.drop(['id', 'event_type', 'pdf_name','paper_text'], axis=1)\n",
        "\n",
        "# Print out the first few rows of dataframe \n",
        "final_dataset.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>2000</td>\n",
              "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
              "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>2001</td>\n",
              "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
              "      <td>Spike-triggered averaging techniques are effec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2384</th>\n",
              "      <td>2007</td>\n",
              "      <td>Competition Adds Complexity</td>\n",
              "      <td>It is known that determinining whether a DEC-P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>2007</td>\n",
              "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
              "      <td>We present the first truly polynomial algorith...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2388</th>\n",
              "      <td>2007</td>\n",
              "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
              "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  ...                                           abstract\n",
              "941   2000  ...  Non-negative matrix factorization (NMF) has pr...\n",
              "1067  2001  ...  Spike-triggered averaging techniques are effec...\n",
              "2384  2007  ...  It is known that determinining whether a DEC-P...\n",
              "2385  2007  ...  We present the first truly polynomial algorith...\n",
              "2388  2007  ...  Semi-supervised inductive learning concerns ho...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amor6IA7OgQZ",
        "outputId": "6eeda7be-4e09-4a4a-cef8-636e467f0a1b"
      },
      "source": [
        "#lets check the abstract feature \n",
        "final_dataset['abstract']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "941     Non-negative matrix factorization (NMF) has pr...\n",
              "1067    Spike-triggered averaging techniques are effec...\n",
              "2384    It is known that determinining whether a DEC-P...\n",
              "2385    We present the first truly polynomial algorith...\n",
              "2388    Semi-supervised inductive learning concerns ho...\n",
              "                              ...                        \n",
              "6943    We revisit the classical analysis of generativ...\n",
              "6944    PAC maximum                                   ...\n",
              "6945    Community detection, which focuses on clusteri...\n",
              "6946    We propose a general framework for interactive...\n",
              "6947    We consider maximum likelihood estimation of l...\n",
              "Name: abstract, Length: 3924, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx0r9o_3fz1G"
      },
      "source": [
        "## **LSH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBSKTy3klU9R"
      },
      "source": [
        "#load english language module of spacy\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# get stop words list\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "\n",
        "# set permutations\n",
        "permutations = 128"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkiC9LIiLWbl"
      },
      "source": [
        "#lets create shringles based on whitespaces and then remove stop words \n",
        "# if required, we can also convert to canonical form using lemmatization, here not doing it.\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    #convert to lower case\n",
        "    tokens = text.lower()\n",
        "    #split into tokens\n",
        "    tokens = tokens.split()\n",
        "    cleaned=[]\n",
        "    for x in tokens:\n",
        "      if not x in (stopwords):      \n",
        "          cleaned.append('{a}'.format(a=x))\n",
        "    #return the canonical form\n",
        "    return ' '.join(cleaned)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbJxHL05O6fC"
      },
      "source": [
        "def get_forest(final_dataset, perms):\n",
        "    minhash = []\n",
        "    for text in final_dataset['abstract']:\n",
        "        tokens = preprocess(text)\n",
        "        m = MinHash(num_perm=perms)\n",
        "        for s in tokens:\n",
        "            m.update(s.encode('utf8'))\n",
        "        minhash.append(m)\n",
        "    forest = MinHashLSHForest(num_perm=perms)\n",
        "    for i,m in enumerate(minhash):\n",
        "        forest.add(i,m)\n",
        "    forest.index()    \n",
        "    return forest"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQvp_XKtPCAn"
      },
      "source": [
        "def predict(text, database, perms, num_results, forest):\n",
        "    tokens = preprocess(text)\n",
        "    m = MinHash(num_perm=perms)\n",
        "    for s in tokens:\n",
        "        m.update(s.encode('utf8'))    \n",
        "    idx_array = np.array(forest.query(m, num_results))\n",
        "    if len(idx_array) == 0:\n",
        "        return None # if your query is empty, return none\n",
        "    result = database.iloc[idx_array]['title']    \n",
        "    return result"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ntCm_FPHZe"
      },
      "source": [
        "#get the forest\n",
        "forest = get_forest(final_dataset, permutations)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A78U4qAlPwCX",
        "outputId": "34f4f753-4787-4a5a-a437-7e5750e1e1ef"
      },
      "source": [
        "# choose the no.of recommendations\n",
        "num_recommendations = 10\n",
        "\n",
        "#select the title for which we need recommendations\n",
        "title = 'Algorithms for Non-negative Matrix Factorization'\n",
        "\n",
        "print(\"The Most Similar Papers To: '{title}' are listed below:\".format(title=title))\n",
        "\n",
        "#get the results by running predict\n",
        "result = predict(title, final_dataset, permutations, num_recommendations, forest)\n",
        "print(\"\\n\")\n",
        "print(\"#\"*100)\n",
        "for x,y in enumerate(result):\n",
        "    print(\"{x}.) {y}\".format(x=x+1,y=y))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Similar Papers To: 'Algorithms for Non-negative Matrix Factorization' are listed below:\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "1.) Diverse Sequential Subset Selection for Supervised Video Summarization\n",
            "2.) Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces\n",
            "3.) An online Hebbian learning rule that performs Independent Component Analysis\n",
            "4.) Subject independent EEG-based BCI decoding\n",
            "5.) Premise Selection for Theorem Proving by Deep Graph Embedding\n",
            "6.) From Deformations to Parts: Motion-based Segmentation of 3D Objects\n",
            "7.) Facial Expression Transfer with Input-Output Temporal Restricted Boltzmann Machines\n",
            "8.) Saliency, Scale and Information: Towards a Unifying Theory\n",
            "9.) Convergence of Monte Carlo Tree Search in Simultaneous Move Games\n",
            "10.) Solid Harmonic Wavelet Scattering: Predicting Quantum Molecular Energy from Invariant Descriptors of 3D  Electronic Densities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EokOAe5MpMc"
      },
      "source": [
        "## **Using Google Universal Sentence Encoder to create vectors prior trying out other ANN alogrithms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7BGBi9TMoqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78da9d5e-8b04-4d3e-90c2-bb6415715d7d"
      },
      "source": [
        "# going to use medium English language module of universal sentence encoder using Spacy(Make use of Google's Universal Sentence Encoder directly within spaCy)\n",
        "nlp = spacy_universal_sentence_encoder.load_model('en_use_md')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kGeQsXsNA2b"
      },
      "source": [
        "#picking the abstract for all papers and converting it to vector\n",
        "abstract = final_dataset.iloc[:,2].values\n",
        "vector_for_abstract_title=[]\n",
        "for x in abstract:\n",
        "  vector_for_abstract_title.append(nlp(x).vector)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v130p31wNre4"
      },
      "source": [
        "#creating dictionary with title and abstract vectors\n",
        "final=dict()\n",
        "final['title'] = final_dataset.iloc[:,1].values\n",
        "final['abstract_vector']=np.array(vector_for_abstract_title)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNOY_kGdREMj",
        "outputId": "dc90b5e2-03f1-4689-d8db-6efa0bf4c99d"
      },
      "source": [
        "#title stored as numpy array\n",
        "final['title']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Algorithms for Non-negative Matrix Factorization',\n",
              "       'Characterizing Neural Gain Control using Spike-triggered Covariance',\n",
              "       'Competition Adds Complexity', ...,\n",
              "       'On clustering network-valued data',\n",
              "       'A General Framework for Robust Interactive Learning',\n",
              "       'Multi-view Matrix Factorization for Linear Dynamical System Estimation'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5V20wjdOzqf",
        "outputId": "f9090c87-d738-4dad-d14a-13ec611bed1a"
      },
      "source": [
        "#view the shape of vector created by universal sentence encoder\n",
        "final['abstract_vector'].shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3924, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVrsYa80O7hg"
      },
      "source": [
        "**As it can be seen whether it is a word, sentence or phrase, the sentence encoder is able to give an embedding vector of size 512**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEtPBQTPNx7F"
      },
      "source": [
        "## **Trying out Other ANN Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_NBFklifu6E"
      },
      "source": [
        "## **Exhaustive Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5llnbeTVddfn"
      },
      "source": [
        "#exaustive search class\n",
        "class Exhaustive():\n",
        "    def __init__(self, vectors, labels):\n",
        "      #get the shape of the vector\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self):\n",
        "          #faiss.IndexFlatL2 slices the input vectors in chunks smaller than blocksize_add and calls add_core\n",
        "        self.index = faiss.IndexFlatL2(self.dimension,)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=11):\n",
        "        distances, indices = self.index.search(vectors, k)\n",
        "        # I expect only query on one vector thus the slice\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB-jJdAQe5ut"
      },
      "source": [
        "#create object for the class and call the build function\n",
        "index = Exhaustive(final[\"abstract_vector\"], final['title'])\n",
        "index.build()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Cp3i0KfH-9",
        "outputId": "08d846e4-2c5d-4967-d0de-785c8c7816a5"
      },
      "source": [
        "#extract the top 10 similar papers for a topic\n",
        "paper_abstract = final['abstract_vector'][0:1]\n",
        "print(\"The Most Similar Papers To: '{paper_title}' are listed below:\".format(paper_title=final['title'][0]))\n",
        "print(\"\\n\")\n",
        "print(\"#\"*100)\n",
        "for x,y in enumerate(index.query(paper_abstract)):\n",
        "  if x!=0:\n",
        "    print(\"{x}.) {y}\".format(x=x,y=y))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Similar Papers To: 'Algorithms for Non-negative Matrix Factorization' are listed below:\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "1.) Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization\n",
            "2.) Orthogonal NMF through Subspace Exploration\n",
            "3.) Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation\n",
            "4.) Newton-Stein Method: A Second Order Method for GLMs via Stein's Lemma\n",
            "5.) On Algorithms for Sparse Multi-factor NMF\n",
            "6.) Approximation Algorithms for \n",
            "7.) A New Alternating Direction Method for Linear Programming\n",
            "8.) Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition\n",
            "9.) Stochastic Variance Reduction Methods for Saddle-Point Problems\n",
            "10.) Convergence and Energy Landscape for Cheeger Cut Clustering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yai95nIFk0vI"
      },
      "source": [
        "## **Annoy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g780SS7f2of"
      },
      "source": [
        "#annoy class\n",
        "class AnnoyIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self, number_of_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimension)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "        \n",
        "    def query(self, vector, k=11):\n",
        "        indices = self.index.get_nns_by_vector(\n",
        "              vector.tolist(), \n",
        "              k)                                           \n",
        "        return [self.labels[i] for i in indices]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNQ0DHNWhYE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07456665-a704-4b3b-f443-1d9592488a73"
      },
      "source": [
        "#build the annoy index\n",
        "index = AnnoyIndex(final[\"abstract_vector\"], final[\"title\"])\n",
        "index.build()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxU0-R9WVukt",
        "outputId": "2db1e519-0473-4a41-dcb5-32a132793d78"
      },
      "source": [
        "#extract the top 10 similar papers for a topic\n",
        "\n",
        "paper_abstract=index.query(final[\"abstract_vector\"][0])\n",
        "\n",
        "print(\"The Most Similar Papers To: '{paper_title}' are listed below:\".format(paper_title=paper_abstract[0]))\n",
        "print(\"\\n\")\n",
        "print(\"#\"*100)\n",
        "for x,y in enumerate(paper_abstract):\n",
        "  if x!=0:\n",
        "    print(\"{x}.) {y}\".format(x=x,y=y))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Similar Papers To: 'Algorithms for Non-negative Matrix Factorization' are listed below:\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "1.) Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization\n",
            "2.) Orthogonal NMF through Subspace Exploration\n",
            "3.) Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation\n",
            "4.) On Algorithms for Sparse Multi-factor NMF\n",
            "5.) Approximation Algorithms for \n",
            "6.) A New Alternating Direction Method for Linear Programming\n",
            "7.) Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition\n",
            "8.) Stochastic Variance Reduction Methods for Saddle-Point Problems\n",
            "9.) Convergence and Energy Landscape for Cheeger Cut Clustering\n",
            "10.) Sum-of-Squares Lower Bounds for Sparse PCA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQQTxtXZk55m"
      },
      "source": [
        "## **HNSW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHs5eQ5mk4oJ"
      },
      "source": [
        "#hnsw class created using using nmslib\n",
        "class NMSLIBIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "        \n",
        "    def query(self, vector, k=11):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyvy6hUGlWzW"
      },
      "source": [
        "#built the grpah\n",
        "index = NMSLIBIndex(final[\"abstract_vector\"], final['title'])\n",
        "index.build()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2xcnVZIllqx",
        "outputId": "b73d4f4c-247b-47c4-d3d6-8449caf1d62f"
      },
      "source": [
        "#extract the top 10 similar papers for a topic\n",
        "\n",
        "paper_abstract=index.query(final[\"abstract_vector\"][0])\n",
        "\n",
        "print(\"The Most Similar Papers To: '{paper_title}' are listed below:\".format(paper_title=paper_abstract[0]))\n",
        "print(\"\\n\")\n",
        "print(\"#\"*100)\n",
        "for x,y in enumerate(paper_abstract):\n",
        "  if x!=0:\n",
        "    print(\"{x}.) {y}\".format(x=x,y=y))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Similar Papers To: 'Algorithms for Non-negative Matrix Factorization' are listed below:\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "1.) Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization\n",
            "2.) Orthogonal NMF through Subspace Exploration\n",
            "3.) Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation\n",
            "4.) Newton-Stein Method: A Second Order Method for GLMs via Stein's Lemma\n",
            "5.) On Algorithms for Sparse Multi-factor NMF\n",
            "6.) Approximation Algorithms for \n",
            "7.) A New Alternating Direction Method for Linear Programming\n",
            "8.) Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition\n",
            "9.) Stochastic Variance Reduction Methods for Saddle-Point Problems\n",
            "10.) Convergence and Energy Landscape for Cheeger Cut Clustering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMAE4U-imPKd"
      },
      "source": [
        "## **Product Quantization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FEM3xsxl7Ji"
      },
      "source": [
        "#product quantization class using faiss\n",
        "class IVPQIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "    def build(self, \n",
        "              number_of_partition=8, \n",
        "              search_in_x_partitions=2, \n",
        "              subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimension)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, \n",
        "                                      self.dimension, \n",
        "                                      number_of_partition, \n",
        "                                      search_in_x_partitions, \n",
        "                                      subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        # I expect only query on one vector thus the slice\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LwoLDpqmpTk"
      },
      "source": [
        "#build the index\n",
        "index = IVPQIndex(final[\"abstract_vector\"], final['title'])\n",
        "index.build()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXKCT2grnWg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb6f9dd-0635-456d-b560-0e8338d59126"
      },
      "source": [
        "#extract the top 10 similar papers for a topic\n",
        "paper_abstract = final['abstract_vector'][0:1]\n",
        "print(\"The Most Similar Papers To: '{paper_title}' are listed below:\".format(paper_title=final['title'][0]))\n",
        "print(\"\\n\")\n",
        "print(\"#\"*100)\n",
        "for x,y in enumerate(index.query(paper_abstract)):\n",
        "  if x!=0:\n",
        "    print(\"{x}.) {y}\".format(x=x,y=y))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Similar Papers To: 'Algorithms for Non-negative Matrix Factorization' are listed below:\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "1.) On Learning Rotations\n",
            "2.) A Non-convex One-Pass Framework for Generalized Factorization Machine and Rank-One Matrix Sensing\n",
            "3.) Scalable Methods for Nonnegative Matrix Factorizations of Near-separable Tall-and-skinny Matrices\n",
            "4.) Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms\n",
            "5.) On Algorithms for Sparse Multi-factor NMF\n",
            "6.) CMA-ES with Optimal Covariance Update and Storage Complexity\n",
            "7.) Mistake Bounds for Binary Matrix Completion\n",
            "8.) Deterministic Symmetric Positive Semidefinite Matrix Completion\n",
            "9.) Algorithms for Non-negative Matrix Factorization\n"
          ]
        }
      ]
    }
  ]
}